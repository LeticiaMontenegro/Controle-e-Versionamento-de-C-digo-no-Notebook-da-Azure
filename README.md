

##  Projeto: Controle e Versionamento de C√≥digo no Notebook da Azure

###  Descri√ß√£o

Este projeto faz parte do desafio **"Controle e Versionamento de C√≥digo no Notebook da Azure"** da plataforma **DIO (Digital Innovation One)**.
O objetivo foi explorar o ambiente do **Azure Databricks**, criar um **notebook em Pandas** e realizar opera√ß√µes de **an√°lise e filtragem de dados com o Apache Spark**.

Durante a pr√°tica, foi realizado um filtro para selecionar apenas os produtos da categoria **"Mountain Bikes"** e visualizar as informa√ß√µes principais, como *ProductID*, *ProductName*, *Category* e *ListPrice*.

---

###  Objetivo do Projeto

* Criar e executar um **notebook Python** dentro do **Azure Databricks**;
* Praticar comandos b√°sicos de an√°lise com **Apache Spark**;
* Entender o processo de filtragem de dados com DataFrames;
* Versionar o projeto no **GitHub** para compor o portf√≥lio t√©cnico.

---

###  Tecnologias Utilizadas

* **Microsoft Azure**
* **Azure Databricks**
* **Apache Spark**
* **Python (pandas e pyspark)**
* **Git e GitHub**

---

###  Etapas Realizadas

1. Cria√ß√£o do workspace no Azure Databricks;
2. Abertura de um notebook Python;
3. Carregamento do dataset products.csv hospedado no GitHub;
4. Convers√£o de pandas DataFrame para Spark DataFrame;
5. Aplica√ß√£o de filtro para a categoria "Mountain Bikes";
6. Visualiza√ß√£o dos resultados e registro no GitHub.

---

###  Ajuste T√©cnico Importante

Durante a execu√ß√£o, foi identificado um problema na visualiza√ß√£o dos dados em formato gr√°fico, pois o Databricks Serverless n√£o permite acesso direto ao sistema de arquivos local do cluster.

Para contornar essa limita√ß√£o e garantir a correta visualiza√ß√£o dos dados:

O dataset foi carregado inicialmente como um pandas DataFrame;

Em seguida, foi convertido para um Spark DataFrame, permitindo aproveitar o poder de processamento distribu√≠do do cluster e a visualiza√ß√£o nativa do Databricks (otimizada para Spark).

```Pandas
# IMPORTANDO ARQUIVO CSV EM PANDAS CONVERTE PARA SPARK "
import pandas as pd

df_pd = pd.read_csv("https://raw.githubusercontent.com/MicrosoftLearning/mslearn-databricks/main/data/products.csv")
df_spark = spark.createDataFrame(df_pd)
display(df_spark)

# Filtrando apenas produtos da categoria "Mountain Bikes"

df_mountain_bikes_spark = df_spark.filter(df_spark.Category == "Mountain Bikes")
display(df_mountain_bikes_spark)display(df_mountain_bikes)
```

---

### üìä Resultado

A consulta retornou os produtos da categoria **Mountain Bikes**, exibindo informa√ß√µes como *ProductID*, *ProductName*, *Category* e *ListPrice*.

| ProductID | ProductName             | Category       | ListPrice |
| --------- | ----------------------- | -------------- | --------- |
| 771       | Mountain-100 Silver, 38 | Mountain Bikes | 3399.99   |
| 772       | Mountain-100 Silver, 42 | Mountain Bikes | 3399.99   |
| ...       | ...                     | ...            | ...       |

---

### üì∏ Evid√™ncias do Projeto

üìå **1Ô∏è‚É£ Notebook criado e executado no Azure Databricks**

> Mostra o notebook com o DataFrame carregado e a execu√ß√£o do c√≥digo Python.
> ![Notebook no Databricks](notebook_criado.png.png)

üìå **2Ô∏è‚É£ Importando Aquivo Cvs e Converter para Spark‚Äù**

> Exibe o resultado  da importa√ß√£o do Csv .
> ![Importacao csv ](importando_csv.png.png)

üìå **3Ô∏è‚É£ Filtragem dos produtos da categoria ‚ÄúMountain Bikes‚Äù**

> Exibe o resultado do filtro aplicado no DataFrame com os produtos e pre√ßos listados.
> ![Filtro por categoria Mountain Bikes](filtrando_categoria.png.png)

---

### Insights e Aprendizados

Aprendi sobre a diferen√ßa entre pandas e Spark DataFrames e quando cada um √© mais adequado.
Entendi como o Databricks Serverless gerencia o acesso ao sistema de arquivos e por que a convers√£o para Spark √© necess√°ria.
Explorei a visualiza√ß√£o nativa do Databricks, que √© mais eficiente e interativa com Spark.
Reforcei a import√¢ncia de versionar notebooks e documentar as decis√µes t√©cnicas no processo.

---



